{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><b>Statistique en Bioinformatique : </b> TME 4  et 5 </h1>\n",
    "<br>\n",
    "L’objectif de ce TME est: \n",
    "<br>\n",
    "<ul>\n",
    "<li> implémenter l'algorithme de Viterbi et l'estimation des paramètres (en utilisant le Viterbi training)\n",
    "pour l'exemple du occasionally dishonest casino.   </li> \n",
    "</ul>\n",
    "<br>\n",
    "<div class=\"alert alert-warning\" role=\"alert\" style=\"margin: 10px\">\n",
    "<p>**Soumission**</p>\n",
    "<ul>\n",
    "<li>Renomer le fichier TME4_5.ipynb pour TME4_5_NomEtudiant1_NomEtudiant2.ipynb </li>\n",
    "<li>Soumettre à https://www.dropbox.com/request/ZylCDDpggbrN5toTiJKV </li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom etudiant 1 :\n",
    "<br>\n",
    "Nom etudiant 2 :\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "Un casino parfois malhonnête (occasionally dishonest casino) utilise 2 types de pieces : fair et unfair. <br>\n",
    "La matrice de transition entre les états cachés est:<br>\n",
    "${\\cal S}=\\{F,U\\}$ (fair, unfair):\n",
    "$$\n",
    "p = \\left(\n",
    "\\begin{array}{cc}\n",
    "0.99 & 0.01\\\\\n",
    "0.05 & 0.95\n",
    "\\end{array}\n",
    "\\right)\\ ,\n",
    "$$\n",
    "\n",
    "les probabilités d'éemission des symboles \n",
    "${\\cal O} = \\{H,T\\}$ (head, tail):\n",
    "\\begin{eqnarray}\n",
    "e_F(H) =  0.5 &\\ \\ \\ \\ &\n",
    "e_F(T) = 0.5 \\nonumber\\\\\n",
    "e_U(H) = 0.9 &\\ \\ \\ \\ &\n",
    "e_U(T) = 0.1 \\nonumber\n",
    "\\end{eqnarray}\n",
    "\n",
    "<br> Et la condition initiale $\\pi^{(0)} = (1,0)$ (le jeux commence toujours avec le pieces juste (fair)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 1</b>:\n",
    "<u>Simulation</u>: Ecrire une fonction qui simule $T$ jets de pieces. \n",
    "La fonction renverra un tableau à deux colonnes correspondant \n",
    "aux valeurs simulées pour les états cachés $X_t$ \n",
    "(type de dés utilisée, “F” ou “U”) et aux symboles observées $Y_t$ \n",
    "(résultat du jet de dés, “H” ou “T”). On simulera une séquence\n",
    "de longueur 2000 qu'on gardera pour les applications ultérieures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "S = {0: \"F\", 1: \"U\"}\n",
    "Pij = np.array([[0.99, 0.01], [0.05, 0.95]])\n",
    "\n",
    "O = {0: \"H\", 1: \"T\"}\n",
    "Eij = np.array([[0.5, 0.5], [0.9, 0.1]])  # ça aurait dû être Eio\n",
    "\n",
    "# Condition initiale\n",
    "pi0 = np.array([0.999, 0.001])\n",
    "\n",
    "T = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def simule(pi0,Eij,Pij,T):\n",
    "    s = np.where(np.cumsum(pi0)>random.random())[0][0]\n",
    "    table = np.zeros((T,2), dtype=np.int64)\n",
    "    for i in range(T-1):\n",
    "        throw = np.where(np.cumsum(Eij[s])>random.random())[0][0]\n",
    "        table[i]=[s,throw]\n",
    "        s=np.where(np.cumsum(Pij[s])>random.random())[0][0]\n",
    "    return table\n",
    "\n",
    "seq=simule(pi0,Eij,Pij,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 2</b>: <u>Algorithme de Viterbi </u>: Ecrire une fonction qui permet\n",
    "de déterminer la séquence $(i^\\star_t)_{t=0:T}$ d'états cachés\n",
    "plus probable, ansi que sa probabilité. Pour tester votre fonction utiliser le résultat de la \n",
    "simulation (2éme colonne) de la question 1. Comparer $(i^\\star_t)_{t=0:T}$ avec\n",
    "les vrais états cachés (1ère colonne de la simulation). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Algorithme de Viterbi\n",
    "def viterbi(obs, Pi, A, B):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    obs : array (T,)\n",
    "        Sequence d'observations.\n",
    "    Pi: array, (K,)\n",
    "        Distribution de probabilite initiale\n",
    "    A : array (K, K)\n",
    "        Matrice de transition\n",
    "    B : array (K, M)\n",
    "        Matrice d'emission matrix\n",
    "\n",
    "    \"\"\"\n",
    "    ## initialisation\n",
    "    psi = np.zeros((len(A), len(obs)))  # A = N\n",
    "    psi[:, 0] = -1\n",
    "    delta = np.zeros(\n",
    "        (len(A), len(obs))\n",
    "    ) \n",
    "\n",
    "    for i in range(len(psi[:, 0])):\n",
    "        delta[i, 0] = np.log(Pi[i]) + np.log(B[i, obs[0]])\n",
    "\n",
    "    ## fin initialisation\n",
    "\n",
    "    for t in range(1, delta.shape[1]):\n",
    "        for e in range(delta.shape[0]):\n",
    "\n",
    "            values = np.zeros(delta.shape[0])\n",
    "\n",
    "            for i in range(delta.shape[0]):\n",
    "                values[i] = delta[i, t - 1] + np.log(A[i, e])\n",
    "\n",
    "            val_max = np.amax(values)\n",
    "            index_max = np.argmax(values)\n",
    "\n",
    "            delta[e, t] = val_max + np.log(B[e, obs[t]])\n",
    "\n",
    "            psi[e, t] = index_max\n",
    "\n",
    "    C = np.zeros(len(obs),dtype=np.int64)\n",
    "    C[-1] = np.argmax(delta[:, -1])\n",
    "\n",
    "    for i in range(len(obs) - 2, -1, -1):\n",
    "        C[i] = psi[C[i + 1].astype(\"int\"), i + 1]\n",
    "\n",
    "    return C,np.amax(delta[:, -1])\n",
    "\n",
    "\n",
    "\n",
    "print(list(viterbi(seq[:,1], pi0, Pij, Eij)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Exercice 3</b>: <u>Estimation des paramètres</u>\n",
    "<br>\n",
    "3.1) Ecrire une fonction qui utilise tous les résultats de la simulation\n",
    "(états et symboles) pour compter les nombres d'occurrence $N_{ij}$ est $M_{iO}$ définis\n",
    "en cours. Estimer $p_{ij}$ est $e_i(O)$, voir slides  37-39 dans la presentation. Attention, pour eviter les probabilites à zero nous alons utiliser les pseudo-count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99384099 0.00615901]\n",
      " [0.0462963  0.9537037 ]]\n",
      "[[0.50643537 0.49356463]\n",
      " [0.88479263 0.11520737]]\n",
      "[9.999e-01 1.000e-04]\n"
     ]
    }
   ],
   "source": [
    "# Estimation de Parametres par contage\n",
    "def param(hidden_states,obs,size_states,size_symbols):\n",
    "\n",
    "    A= np.ones((size_states,size_states))\n",
    "    B = np.ones((size_states, size_symbols))\n",
    "    for i in range(1,len(hidden_states)-1):\n",
    "        p=(hidden_states[i-1],hidden_states[i])\n",
    "        A[p[0],p[1]] +=1\n",
    "    A = A/np.maximum(A.sum(1).reshape(size_states, 1), 1)\n",
    "    \n",
    "    for i in range(len(obs)):\n",
    "        B[hidden_states[i], obs[i]] += 1\n",
    "\n",
    "    for b in range(len(B)):\n",
    "        B[b, :] = B[b, :] / B[b, :].sum()\n",
    "    Pi = np.full(size_states,0.0001)     \n",
    "    Pi[hidden_states[0]]=0.9999\n",
    "    return A,B,Pi\n",
    "A,B,Pi = param(seq[:,0], seq[:,1],2,2)\n",
    "print(A)\n",
    "print(B)\n",
    "print(Pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) <u> Viterbi training </u>: Ecrire une fonction qui utilise \n",
    "seulement la séquence $(O_t)_{t=0:T}$ (2emme colone de la simulation) pour estimer les \n",
    "paramètres $p_{ij}$ est $e_i(O)$. On s'arretera quand les diferences entre les logVraissamblance est inferieur à 1e-04. Comparer les résultats de 3.1 et de 3.2 (3.2 avec plusieurs restarts,\n",
    "et avec initialisation des paramètres alèatoire).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation :\n",
      "\n",
      "Pij :\n",
      "[[0.79556741 0.55514478]\n",
      " [0.20443259 0.44485522]]\n",
      "Eij :\n",
      "[[0.84164989 0.15835011]\n",
      " [0.46106805 0.53893195]]\n",
      "Pi0 :\n",
      "[0.30774884 0.69225116]\n",
      "-2036.3517378830313\n",
      "\n",
      "Training ...\n",
      "\n",
      "vraissamblance :-1609.4355892378264 at step 1\n",
      "vraissamblance :-1609.4355892378264 at step 2\n",
      "\n",
      "last estimation :\n",
      "\n",
      "Pij :\n",
      "[[0.85289958 0.14710042]\n",
      " [0.3537415  0.6462585 ]]\n",
      "Eij :\n",
      "[[0.8319209  0.1680791 ]\n",
      " [0.00170068 0.99829932]]\n",
      "Pi0 :\n",
      "[9.999e-01 1.000e-04]\n",
      "vraissamblance :\n",
      "-1609.4355892378264\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def viterbi_training(obs,size_states,affichage=False):\n",
    "    \n",
    "    # Initialisation aleatoire de Pij, Eij, pi0\n",
    "    \n",
    "    Estimate_Pij=np.random.rand(size_states,size_states)\n",
    "    for a in range(len(Estimate_Pij)):\n",
    "        Estimate_Pij[:,a] = Estimate_Pij[:,a] / Estimate_Pij[:, a].sum()\n",
    "    \n",
    "    Estimate_Eij=np.random.rand(size_states,size_states)\n",
    "    for b in range(len(Estimate_Eij)):\n",
    "        Estimate_Eij[b, :] = Estimate_Eij[b, :] / Estimate_Eij[b, :].sum()\n",
    "    Estimate_pi0=np.random.rand(size_states)\n",
    "    Estimate_pi0=Estimate_pi0/Estimate_pi0.sum()\n",
    "    # Calcule log Vraissamblance\n",
    "    hiden_state,vraissamblance_after = viterbi(obs, Estimate_pi0, Estimate_Pij, Estimate_Eij)\n",
    "    vraissamblance_before = 1000\n",
    "    \n",
    "    if affichage:\n",
    "        print(\"Initialisation :\")\n",
    "        print(\"\")\n",
    "        print(\"Pij :\")\n",
    "        print(Estimate_Pij)\n",
    "        print(\"Eij :\")\n",
    "        print(Estimate_Eij)\n",
    "        print(\"Pi0 :\")\n",
    "        print(Estimate_pi0)\n",
    "        print(vraissamblance_after)\n",
    "        print(\"\")\n",
    "        print(\"Training ...\")\n",
    "        print(\"\")\n",
    "        \n",
    "    # Viterbi Training\n",
    "    step = 0\n",
    "    while np.abs(vraissamblance_after-vraissamblance_before) >= 10**-4:\n",
    "        vraissamblance_before = vraissamblance_after\n",
    "        Estimate_Pij,Estimate_Eij,Estimate_pi0=param(hiden_state,obs,size_states,size_states)\n",
    "        hiden_state,vraissamblance_after = viterbi(obs, Estimate_pi0, Estimate_Pij, Estimate_Eij)\n",
    "        step+=1\n",
    "        if affichage:\n",
    "            print(\"vraissamblance :\"+str(vraissamblance_after)+\" at step \"+str(step))\n",
    "\n",
    "    return Estimate_Pij,Estimate_Eij,Estimate_pi0,vraissamblance_after\n",
    "\n",
    "obs=seq[:,1]\n",
    "\n",
    "Estimate_Pij,Estimate_Eij,Estimate_pi0,vraissamblance = viterbi_training(obs,2, affichage = True)\n",
    "print(\"\")\n",
    "print(\"last estimation :\")\n",
    "print(\"\")\n",
    "print(\"Pij :\")\n",
    "print(Estimate_Pij)\n",
    "print(\"Eij :\")\n",
    "print(Estimate_Eij)\n",
    "print(\"Pi0 :\")\n",
    "print(Estimate_pi0)\n",
    "print(\"vraissamblance :\")\n",
    "print(vraissamblance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3) <u>Viterbi training deuxiemme version </u> Ecrivez une version de 3.3 qui:\n",
    "- part plusieurs fois (100x) d'une initialisation aléatoire des \n",
    "paramètres de l'HMM,\n",
    "- utilise Viterbi training pour estimer les paramètres,\n",
    "- calcule la log-vraisemblance pour les paramètres estimés,\n",
    "- sauvegarde seulement l'estimation avec la valeur maximale de la\n",
    "log-vraisemblance.\n",
    "\n",
    "Qu'est-ce que vous observez?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-1355.6734681810485\n",
      "-1355.6734681810485\n",
      "-1355.6734681810485\n",
      "-1355.6734681810485\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1345.091060553129\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n",
      "-1344.5983788377766\n"
     ]
    }
   ],
   "source": [
    "# Viterbi Training  deuxiemme version\n",
    "\n",
    "max_vraissamblance = -np.inf\n",
    "\n",
    "for i in range(100):\n",
    "    Estimate_Pij,Estimate_Eij,Estimate_pi0,vraissamblance_after = viterbi_training(obs,2)\n",
    "    if vraissamblance_after>max_vraissamblance:\n",
    "        max_vraissamblance = vraissamblance_after\n",
    "        maxEstimate_Pij,maxEstimate_Eij,maxEstimate_pi0,maxvraissamblance_after=Estimate_Pij,Estimate_Eij,Estimate_pi0,vraissamblance_after\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1344.5983788377766\n",
      "[[0.97385621 0.02614379]\n",
      " [0.00216333 0.99783667]] \n",
      " [[0.92156863 0.07843137]\n",
      " [0.56077796 0.43922204]] \n",
      " [1.000e-04 9.999e-01] \n",
      " -1344.5983788377766\n"
     ]
    }
   ],
   "source": [
    "print(max_vraissamblance)\n",
    "print(maxEstimate_Pij,\"\\n\",maxEstimate_Eij,\"\\n\",maxEstimate_pi0,\"\\n\",maxvraissamblance_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
